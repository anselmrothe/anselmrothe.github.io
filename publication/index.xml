<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications on Anselm Rothe</title>
    <link>https://anselmrothe.github.io/publication/</link>
    <description>Recent content in Publications on Anselm Rothe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://anselmrothe.github.io/publication/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Successful structure learning from observational data</title>
      <link>https://anselmrothe.github.io/publication/2018causalstructure/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://anselmrothe.github.io/publication/2018causalstructure/</guid>
      <description>Abstract Previous work suggests that humans find it difficult to learn the structure of causal systems given observational data alone. We identify two conditions that enable successful structure learning from observational data: people succeed if the underlying causal system is deterministic, and if each pattern of observations has a single root cause. In four experiments, we show that either condition alone is sufficient to enable high levels of performance, but that performance is poor if neither condition applies.</description>
    </item>
    
    <item>
      <title>Do people ask good questions?</title>
      <link>https://anselmrothe.github.io/publication/2018questions/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://anselmrothe.github.io/publication/2018questions/</guid>
      <description>Abstract People ask questions in order to efficiently learn about the world. But do people ask good questions? In this work, we designed an intuitive, game-based task that allowed people to ask natural language questions to resolve their uncertainty. Question quality was measured through Bayesian ideal-observer models that considered large spaces of possible game states. During free-form question generation, participants asked a creative variety of useful and goal-directed questions, yet they rarely asked the best questions as identified by the Bayesian ideal-observers (Experiment 1).</description>
    </item>
    
    <item>
      <title>Topics and trends in cognitive science</title>
      <link>https://anselmrothe.github.io/publication/2018cogsci_dtm/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://anselmrothe.github.io/publication/2018cogsci_dtm/</guid>
      <description>Abstract What are the major topics of the Cognitive Science Society conference? How have they changed over the years? To answer these questions, we applied an unsupervised learning algorithm known as dynamic topic modeling (Blei &amp;amp; Lafferty, 2006) to the 2000–2017 Proceedings of the Cognitive Science Society. Unlike traditional topic models, a dynamic topic model is sensitive to the temporal context of documents and can characterize the evolution of each topic across years.</description>
    </item>
    
    <item>
      <title>Grounding compositional hypothesis generation in specific instances</title>
      <link>https://anselmrothe.github.io/publication/2018cogsci_zendo/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://anselmrothe.github.io/publication/2018cogsci_zendo/</guid>
      <description>Abstract A number of recent computational models treat concept learning as a form of probabilistic rule induction in a space of language-like, compositional concepts. Inference in such models frequently requires repeatedly sampling from a (infinite) distribution over possible concept rules and comparing their relative likelihood in light of current data or evidence. However, we argue that most existing algorithms for top-down sampling are inefficient and cognitively implausible accounts of human hypothesis generation.</description>
    </item>
    
    <item>
      <title>Modeling second-language learning from a psychological perspective</title>
      <link>https://anselmrothe.github.io/publication/2018duolingo/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://anselmrothe.github.io/publication/2018duolingo/</guid>
      <description>Abstract Psychological research on learning and memory has tended to emphasize small-scale laboratory studies. However, large datasets of people using educational software provide opportunities to explore these issues from anew perspective. In this paper we describe our approach to the Duolingo Second Language Acquisition Modeling (SLAM) competition which was run in early 2018. We used a well known class of algorithms (gradient boosted decision trees), with features partially informed by theories from the psychological literature.</description>
    </item>
    
    <item>
      <title>Question asking as program generation</title>
      <link>https://anselmrothe.github.io/publication/2017nips/</link>
      <pubDate>Sun, 03 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://anselmrothe.github.io/publication/2017nips/</guid>
      <description>Abstract A hallmark of human intelligence is the ability to ask rich, creative, and revealing questions. Here we introduce a cognitive model capable of constructing human-like questions. Our approach treats questions as formal programs that, when executed on the state of the world, output an answer. The model specifies a probability distribution over a complex, compositional space of programs, favoring concise programs that help the agent learn in the current context.</description>
    </item>
    
    <item>
      <title>Asking and evaluating natural language questions</title>
      <link>https://anselmrothe.github.io/publication/2016cogsci/</link>
      <pubDate>Fri, 01 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://anselmrothe.github.io/publication/2016cogsci/</guid>
      <description>See the extended version of this project &amp;rarr; here</description>
    </item>
    
    <item>
      <title>Causal status meets coherence: The explanatory role of causal models in categorization</title>
      <link>https://anselmrothe.github.io/publication/2012cogsci/</link>
      <pubDate>Wed, 01 Aug 2012 00:00:00 +0000</pubDate>
      
      <guid>https://anselmrothe.github.io/publication/2012cogsci/</guid>
      <description>Abstract Research on causal-based categorization has found two competing effects: According to the causal-status hypothesis, people consider causally central features more than less central ones. In contrast, people often focus upon feature patterns that are coherent with the category’s causal model (coherence hypothesis). Following up on the proposal that categorization can be seen as inference to the best explanation (e.g., Murphy &amp;amp; Medin, 1985), we propose that causal models might serve different explanatory roles.</description>
    </item>
    
  </channel>
</rss>